"""
ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®è«–æ–‡è¿½åŠ ãƒšãƒ¼ã‚¸

Claude Webãªã©ã§ç”Ÿæˆã—ãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆJSON/YAML/MDï¼‰ã¨PDFã‚’åŒæ™‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
"""

import streamlit as st
import sys
from pathlib import Path
import json
import yaml
from datetime import datetime
import re

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from scripts.utils import PDFProcessor, TagSystem, GitManager

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¿½åŠ ", page_icon="ğŸ“‹", layout="wide")

# åˆæœŸåŒ–
@st.cache_resource
def init_system():
    """ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
    tag_hierarchy_path = project_root / "data" / "tag_hierarchy.json"
    tag_groups_path = project_root / "data" / "tag_groups.json"

    pdf_processor = PDFProcessor()
    tag_system = TagSystem(tag_hierarchy_path, tag_groups_path)

    return pdf_processor, tag_system

pdf_processor, tag_system = init_system()

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ“‹ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¿½åŠ ")

st.markdown("""
Claude Webãªã©ã®AIã§ç”Ÿæˆã—ãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã¨PDFã‚’åŒæ™‚ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è¿½åŠ ã—ã¾ã™ã€‚

**å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: JSON, YAML, Markdown
""")

st.markdown("---")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
col_pdf, col_metadata = st.columns(2)

with col_pdf:
    st.subheader("1ï¸âƒ£ PDFãƒ•ã‚¡ã‚¤ãƒ«")
    uploaded_pdf = st.file_uploader(
        "è«–æ–‡PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=['pdf'],
        help="è«–æ–‡ã®PDFãƒ•ã‚¡ã‚¤ãƒ«"
    )

    if uploaded_pdf:
        st.success(f"âœ“ {uploaded_pdf.name}")
        file_size = uploaded_pdf.size / 1024 / 1024
        st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f} MB")

with col_metadata:
    st.subheader("2ï¸âƒ£ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«")
    uploaded_metadata = st.file_uploader(
        "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=['json', 'yaml', 'yml', 'md', 'txt'],
        help="Claude Webãªã©ã§ç”Ÿæˆã—ãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«"
    )

    if uploaded_metadata:
        st.success(f"âœ“ {uploaded_metadata.name}")

st.markdown("---")

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒ¼ã‚¹é–¢æ•°
def parse_json(content: str) -> dict:
    """JSONã‚’ãƒ‘ãƒ¼ã‚¹"""
    return json.loads(content)

def parse_yaml(content: str) -> dict:
    """YAMLã‚’ãƒ‘ãƒ¼ã‚¹"""
    # YAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’æŠ½å‡ºï¼ˆMarkdownã®å ´åˆï¼‰
    if content.strip().startswith('---'):
        parts = content.split('---', 2)
        if len(parts) >= 3:
            yaml_content = parts[1]
            return yaml.safe_load(yaml_content)

    return yaml.safe_load(content)

def parse_markdown(content: str) -> dict:
    """Markdownã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    # YAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ã†
    if content.strip().startswith('---'):
        return parse_yaml(content)

    # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ãŒãªã„å ´åˆã¯ç°¡æ˜“ãƒ‘ãƒ¼ã‚¹
    metadata = {}

    # ã‚¿ã‚¤ãƒˆãƒ«
    title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
    if title_match:
        metadata['title'] = title_match.group(1)

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çš„ãªæƒ…å ±ã‚’æŠ½å‡º
    lines = content.split('\n')
    for line in lines:
        if ':' in line and not line.strip().startswith('#'):
            key, value = line.split(':', 1)
            key = key.strip().lower().replace(' ', '_')
            value = value.strip()
            metadata[key] = value

    return metadata

def parse_metadata_file(file) -> dict:
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹"""
    content = file.read().decode('utf-8')
    file_name = file.name.lower()

    try:
        if file_name.endswith('.json'):
            return parse_json(content)
        elif file_name.endswith(('.yaml', '.yml')):
            return parse_yaml(content)
        elif file_name.endswith(('.md', '.txt')):
            return parse_markdown(content)
        else:
            st.error(f"æœªå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {file_name}")
            return {}
    except Exception as e:
        st.error(f"ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºãƒ»ç·¨é›†
if uploaded_metadata:
    st.subheader("3ï¸âƒ£ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

    # ãƒ‘ãƒ¼ã‚¹å®Ÿè¡Œ
    metadata = parse_metadata_file(uploaded_metadata)

    if metadata:
        # ã‚¿ãƒ–ã§è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ
        tab_json, tab_edit = st.tabs(["ğŸ“„ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", "âœï¸ ç·¨é›†"])

        with tab_json:
            st.json(metadata)

        with tab_edit:
            st.markdown("**å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã—ã¦ãã ã•ã„**")

            # ä¸»è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç·¨é›†å¯èƒ½ã«
            col_e1, col_e2 = st.columns(2)

            with col_e1:
                metadata['title'] = st.text_input(
                    "ã‚¿ã‚¤ãƒˆãƒ«",
                    value=metadata.get('title', ''),
                    key='edit_title'
                )

                authors_str = ', '.join(metadata.get('authors', [])) if isinstance(metadata.get('authors'), list) else metadata.get('authors', '')
                authors_input = st.text_input(
                    "è‘—è€…ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰",
                    value=authors_str,
                    key='edit_authors'
                )
                metadata['authors'] = [a.strip() for a in authors_input.split(',') if a.strip()]

                metadata['year'] = st.number_input(
                    "å¹´",
                    value=int(metadata.get('year', 2024)) if metadata.get('year') else 2024,
                    min_value=1900,
                    max_value=2100,
                    key='edit_year'
                )

                metadata['journal'] = st.text_input(
                    "ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«",
                    value=metadata.get('journal', ''),
                    key='edit_journal'
                )

            with col_e2:
                # ç ”ç©¶ã‚¿ã‚¤ãƒ—
                study_types = tag_system.get_canonical_tags('study_type')
                current_study_type = metadata.get('study_type', study_types[0])
                if current_study_type not in study_types:
                    study_types.insert(0, current_study_type)

                metadata['study_type'] = st.selectbox(
                    "ç ”ç©¶ã‚¿ã‚¤ãƒ—",
                    options=study_types,
                    index=study_types.index(current_study_type) if current_study_type in study_types else 0,
                    key='edit_study_type'
                )

                # Perspectives
                if 'perspectives' not in metadata:
                    metadata['perspectives'] = {}

                diseases = ["not_applicable"] + tag_system.get_canonical_tags('disease')
                current_disease = metadata.get('perspectives', {}).get('disease', 'not_applicable')
                if current_disease and current_disease not in diseases:
                    diseases.insert(1, current_disease)

                metadata['perspectives']['disease'] = st.selectbox(
                    "Disease",
                    options=diseases,
                    index=diseases.index(current_disease) if current_disease in diseases else 0,
                    key='edit_disease'
                )

                methods = ["not_applicable"] + tag_system.get_canonical_tags('method')
                current_method = metadata.get('perspectives', {}).get('method', 'not_applicable')
                if current_method and current_method not in methods:
                    methods.insert(1, current_method)

                metadata['perspectives']['method'] = st.selectbox(
                    "Method",
                    options=methods,
                    index=methods.index(current_method) if current_method in methods else 0,
                    key='edit_method'
                )

st.markdown("---")

# è¿½åŠ ãƒœã‚¿ãƒ³
if uploaded_pdf and uploaded_metadata and metadata:
    col_btn1, col_btn2 = st.columns([1, 3])

    with col_btn1:
        if st.button("ğŸ“ è«–æ–‡ã‚’è¿½åŠ ", type="primary", use_container_width=True):
            try:
                with st.spinner("è«–æ–‡ã‚’è¿½åŠ ä¸­..."):
                    # Paper IDç”Ÿæˆ
                    catalog_path = project_root / "data" / "catalog.json"
                    with open(catalog_path, 'r', encoding='utf-8') as f:
                        catalog = json.load(f)

                    existing_ids = list(catalog['papers'].keys())
                    if not existing_ids:
                        paper_id = "paper001"
                    else:
                        max_num = max([int(pid.replace("paper", ""))
                                     for pid in existing_ids
                                     if pid.startswith("paper")])
                        paper_id = f"paper{str(max_num + 1).zfill(3)}"

                    # PDFã‚’ä¿å­˜
                    papers_dir = project_root / "papers" / "all_papers"
                    papers_dir.mkdir(parents=True, exist_ok=True)

                    pdf_dest = papers_dir / f"{paper_id}.pdf"
                    with open(pdf_dest, "wb") as f:
                        f.write(uploaded_pdf.getbuffer())

                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
                    metadata['paper_id'] = paper_id
                    metadata['pdf_path'] = str(pdf_dest.absolute())

                    # perspectives.study_type ã‚’è¨­å®š
                    if 'perspectives' not in metadata:
                        metadata['perspectives'] = {}
                    metadata['perspectives']['study_type'] = metadata.get('study_type', '')

                    # ã‚¿ã‚°æ­£è¦åŒ–
                    metadata['perspectives'] = tag_system.normalize_tags(metadata['perspectives'])

                    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                    now = datetime.now().isoformat()
                    metadata['date_added'] = now
                    metadata['date_modified'] = now

                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                    if 'read_status' not in metadata:
                        metadata['read_status'] = 'unread'
                    if 'priority' not in metadata:
                        metadata['priority'] = 'medium'
                    if 'language' not in metadata:
                        metadata['language'] = 'en'

                    # catalog.jsonã«è¿½åŠ 
                    catalog['papers'][paper_id] = metadata

                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã‚’æ›´æ–°
                    catalog['metadata']['total_papers'] = len(catalog['papers'])
                    catalog['metadata']['last_updated'] = now

                    # åˆ†å¸ƒã‚’æ›´æ–°
                    for dist_key in ['study_type', 'disease', 'method', 'analysis', 'population']:
                        distribution = {}
                        for paper_data in catalog['papers'].values():
                            perspectives_data = paper_data.get('perspectives', {})
                            if dist_key in perspectives_data:
                                tag = perspectives_data[dist_key]
                                if tag and tag != "not_applicable":
                                    distribution[tag] = distribution.get(tag, 0) + 1
                        catalog['metadata'][f'{dist_key}_distribution'] = distribution

                    # ä¿å­˜
                    with open(catalog_path, 'w', encoding='utf-8') as f:
                        json.dump(catalog, f, indent=2, ensure_ascii=False)

                    # Obsidianãƒãƒ¼ãƒˆç”Ÿæˆ
                    from scripts.add_paper import PaperAdder

                    config_path = project_root / "config" / "config.yaml"
                    adder = PaperAdder(config_path)
                    adder._create_obsidian_note(paper_id, metadata)
                    adder._update_moc_notes(metadata)

                    st.success(f"âœ… è«–æ–‡ã‚’è¿½åŠ ã—ã¾ã—ãŸ: {paper_id}")
                    st.balloons()

                    # Obsidianã§é–‹ããƒªãƒ³ã‚¯
                    obsidian_note_path = project_root / "ObsidianVault" / "Papers" / f"{paper_id}.md"
                    obsidian_uri = f"obsidian://open?path={obsidian_note_path.absolute()}"

                    st.markdown(f"""
                    ### ğŸ‰ è¿½åŠ å®Œäº†ï¼

                    **Paper ID**: `{paper_id}`

                    **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**:
                    - [ğŸ“– Obsidianã§é–‹ã]({obsidian_uri})
                    - [ğŸ“š ä¸€è¦§ãƒšãƒ¼ã‚¸ã§ç¢ºèª](Browse)
                    """)

            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                import traceback
                st.code(traceback.format_exc())

else:
    st.info("ğŸ“¤ PDFãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸¡æ–¹ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

# ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰
st.markdown("---")
st.subheader("ğŸ’¡ ä½¿ã„æ–¹")

with st.expander("Claude Webã§ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•"):
    st.markdown("""
    ### 1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨

    `scripts/prompts/metadata_generation_prompt.txt` ã®å†…å®¹ã‚’Claude Webã«è²¼ã‚Šä»˜ã‘

    ### 2. è«–æ–‡æƒ…å ±ã‚’å…¥åŠ›

    ã‚¿ã‚¤ãƒˆãƒ«ã€è‘—è€…ã€ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆãªã©ã‚’å…¥åŠ›

    ### 3. ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

    ç”Ÿæˆã•ã‚ŒãŸYAML/JSONã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜

    ### 4. ã“ã®ãƒšãƒ¼ã‚¸ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

    PDFã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒæ™‚ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    """)

with st.expander("å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"):
    st.markdown("""
    ### JSONå½¢å¼
    ```json
    {
      "title": "è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«",
      "authors": ["è‘—è€…1", "è‘—è€…2"],
      "year": 2024,
      "study_type": "rct",
      "perspectives": {
        "disease": "stroke",
        "method": "gait_analysis"
      }
    }
    ```

    ### YAMLå½¢å¼
    ```yaml
    ---
    title: è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«
    authors:
      - è‘—è€…1
      - è‘—è€…2
    year: 2024
    study_type: rct
    perspectives:
      disease: stroke
      method: gait_analysis
    ---
    ```

    ### Markdownå½¢å¼ï¼ˆYAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ä»˜ãï¼‰
    ```markdown
    ---
    title: è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«
    authors: [è‘—è€…1, è‘—è€…2]
    year: 2024
    ---

    # è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«

    å†…å®¹...
    ```
    """)
